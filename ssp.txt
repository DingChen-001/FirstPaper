处理起始目录: S:\Notes\HFUT\Experiment\_228\SSP-AI-Generated-Image-Detection
处理时间: 2025-02-13 15:49:10

└── 文件路径: S:\Notes\HFUT\Experiment\_228\SSP-AI-Generated-Image-Detection\.gitignore
   文件内容:
*.pyc
__pycache__
*.pth
*.log
*.json
*.npy
snapshot

└── 目录: S:\Notes\HFUT\Experiment\_228\SSP-AI-Generated-Image-Detection\figures
  └── 文件路径: S:\Notes\HFUT\Experiment\_228\SSP-AI-Generated-Image-Detection\figures\pipeline.png
     错误: 无法读取文件 S:\Notes\HFUT\Experiment\_228\SSP-AI-Generated-Image-Detection\figures\pipeline.png - 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte

  └── 文件路径: S:\Notes\HFUT\Experiment\_228\SSP-AI-Generated-Image-Detection\figures\results.png
     错误: 无法读取文件 S:\Notes\HFUT\Experiment\_228\SSP-AI-Generated-Image-Detection\figures\results.png - 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte

└── 目录: S:\Notes\HFUT\Experiment\_228\SSP-AI-Generated-Image-Detection\networks
  └── 文件路径: S:\Notes\HFUT\Experiment\_228\SSP-AI-Generated-Image-Detection\networks\resnet.py
     文件内容:
  import torch.nn as nn
import torch.utils.model_zoo as model_zoo
import torch
__all__ = ["ResNet", "resnet18", "resnet34",
           "resnet50", "resnet101", "resnet152"]


model_urls = {
    "resnet18": "https://download.pytorch.org/models/resnet18-5c106cde.pth",
    "resnet34": "https://download.pytorch.org/models/resnet34-333f7ec4.pth",
    "resnet50": "https://download.pytorch.org/models/resnet50-19c8e357.pth",
    "resnet101": "https://download.pytorch.org/models/resnet101-5d3b4d8f.pth",
    "resnet152": "https://download.pytorch.org/models/resnet152-b121ed2d.pth",
}


def conv3x3(in_planes, out_planes, stride=1):
    """3x3 convolution with padding"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)


def conv1x1(in_planes, out_planes, stride=1):
    """1x1 convolution"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)


class BasicBlock(nn.Module):
    expansion = 1

    def __init__(self, inplanes, planes, stride=1, downsample=None):
        super().__init__()
        self.conv1 = conv3x3(inplanes, planes, stride)
        self.bn1 = nn.BatchNorm2d(planes)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = conv3x3(planes, planes)
        self.bn2 = nn.BatchNorm2d(planes)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x):
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)

        if self.downsample is not None:
            identity = self.downsample(x)

        out += identity
        out = self.relu(out)

        return out


class Bottleneck(nn.Module):
    expansion = 4

    def __init__(self, inplanes, planes, stride=1, downsample=None):
        super().__init__()
        self.conv1 = conv1x1(inplanes, planes)
        self.bn1 = nn.BatchNorm2d(planes)
        self.conv2 = conv3x3(planes, planes, stride)
        self.bn2 = nn.BatchNorm2d(planes)
        self.conv3 = conv1x1(planes, planes * self.expansion)
        self.bn3 = nn.BatchNorm2d(planes * self.expansion)
        self.relu = nn.ReLU(inplace=True)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x):
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)
        out = self.relu(out)

        out = self.conv3(out)
        out = self.bn3(out)

        if self.downsample is not None:
            identity = self.downsample(x)

        out += identity
        out = self.relu(out)

        return out


class ResNet(nn.Module):
    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False):
        super().__init__()
        self.inplanes = 64
        self.conv1 = nn.Conv2d(3, 64, kernel_size=7,
                               stride=2, padding=3, bias=False)
        self.bn1 = nn.BatchNorm2d(64)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        self.layer1 = self._make_layer(block, 64, layers[0])
        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)
        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)
        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = nn.Linear(512 * block.expansion, num_classes)

        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(
                    m.weight, mode="fan_out", nonlinearity="relu")
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)

        # Zero-initialize the last BN in each residual branch,
        # so that the residual branch starts with zeros, and each residual block behaves like an identity.
        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677
        if zero_init_residual:
            for m in self.modules():
                if isinstance(m, Bottleneck):
                    nn.init.constant_(m.bn3.weight, 0)
                elif isinstance(m, BasicBlock):
                    nn.init.constant_(m.bn2.weight, 0)

    def _make_layer(self, block, planes, blocks, stride=1):
        downsample = None
        if stride != 1 or self.inplanes != planes * block.expansion:
            downsample = nn.Sequential(
                conv1x1(self.inplanes, planes * block.expansion, stride),
                nn.BatchNorm2d(planes * block.expansion),
            )

        layers = [block(self.inplanes, planes, stride, downsample)]
        self.inplanes = planes * block.expansion
        layers.extend(block(self.inplanes, planes) for _ in range(1, blocks))
        return nn.Sequential(*layers)

    def forward(self, x, *args):
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)

        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)

        x = self.avgpool(x)
        x = x.view(x.size(0), -1)
        x = self.fc(x)

        return x


def resnet18(pretrained=False, **kwargs):
    """Constructs a ResNet-18 model.
    Args:
        pretrained (bool): If True, returns a model pre-trained on ImageNet
    """
    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)
    if pretrained:
        model.load_state_dict(model_zoo.load_url(model_urls["resnet18"]))
    return model


def resnet34(pretrained=False, **kwargs):
    """Constructs a ResNet-34 model.
    Args:
        pretrained (bool): If True, returns a model pre-trained on ImageNet
    """
    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)
    if pretrained:
        model.load_state_dict(model_zoo.load_url(model_urls["resnet34"]))
    return model


def resnet50(pretrained=False, **kwargs):
    """Constructs a ResNet-50 model.
    Args:
        pretrained (bool): If True, returns a model pre-trained on ImageNet
    """
    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)
    if pretrained:
        model.load_state_dict(model_zoo.load_url(model_urls["resnet50"]))
    return model


def resnet101(pretrained=False, **kwargs):
    """Constructs a ResNet-101 model.
    Args:
        pretrained (bool): If True, returns a model pre-trained on ImageNet
    """
    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)
    if pretrained:
        model.load_state_dict(model_zoo.load_url(model_urls["resnet101"]))
    return model


def resnet152(pretrained=False, **kwargs):
    """Constructs a ResNet-152 model.
    Args:
        pretrained (bool): If True, returns a model pre-trained on ImageNet
    """
    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)
    if pretrained:
        model.load_state_dict(model_zoo.load_url(model_urls["resnet152"]))
    return model


if __name__ == '__main__':
    net = resnet50(pretrained=True)
    print(net)


  └── 文件路径: S:\Notes\HFUT\Experiment\_228\SSP-AI-Generated-Image-Detection\networks\srm_conv.py
     文件内容:
  import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np


class SRMConv2d_simple(nn.Module):

    def __init__(self, inc=3, learnable=False):
        super(SRMConv2d_simple, self).__init__()
        self.truc = nn.Hardtanh(-3, 3)
        kernel = self._build_kernel(inc)  # (3,3,5,5)
        self.kernel = nn.Parameter(data=kernel, requires_grad=learnable)
        # self.hor_kernel = self._build_kernel().transpose(0,1,3,2)

    def forward(self, x):
        '''
        x: imgs (Batch, H, W, 3)
        '''
        out = F.conv2d(x, self.kernel, stride=1, padding=2)
        out = self.truc(out)

        return out

    def _build_kernel(self, inc):
        # filter1: KB
        filter1 = [[0, 0, 0, 0, 0],
                   [0, -1, 2, -1, 0],
                   [0, 2, -4, 2, 0],
                   [0, -1, 2, -1, 0],
                   [0, 0, 0, 0, 0]]
        # filter2：KV
        filter2 = [[-1, 2, -2, 2, -1],
                   [2, -6, 8, -6, 2],
                   [-2, 8, -12, 8, -2],
                   [2, -6, 8, -6, 2],
                   [-1, 2, -2, 2, -1]]
        # filter3：hor 2rd
        filter3 = [[0, 0, 0, 0, 0],
                   [0, 0, 0, 0, 0],
                   [0, 1, -2, 1, 0],
                   [0, 0, 0, 0, 0],
                   [0, 0, 0, 0, 0]]

        filter1 = np.asarray(filter1, dtype=float) / 4.
        filter2 = np.asarray(filter2, dtype=float) / 12.
        filter3 = np.asarray(filter3, dtype=float) / 2.
        # statck the filters
        filters = [[filter1],  # , filter1, filter1],
                   [filter2],  # , filter2, filter2],
                   [filter3]]  # , filter3, filter3]]  # (3,3,5,5)
        filters = np.array(filters)
        filters = np.repeat(filters, inc, axis=1)
        filters = torch.FloatTensor(filters)    # (3,3,5,5)
        return filters


class SRMConv2d_Separate(nn.Module):

    def __init__(self, inc, outc, learnable=False):
        super(SRMConv2d_Separate, self).__init__()
        self.inc = inc
        self.truc = nn.Hardtanh(-3, 3)
        kernel = self._build_kernel(inc)  # (3,3,5,5)
        self.kernel = nn.Parameter(data=kernel, requires_grad=learnable)
        # self.hor_kernel = self._build_kernel().transpose(0,1,3,2)
        self.out_conv = nn.Sequential(
            nn.Conv2d(3*inc, outc, 1, 1, 0, 1, 1, bias=False),
            nn.BatchNorm2d(outc),
            nn.ReLU(inplace=True)
        )

        for ly in self.out_conv.children():
            if isinstance(ly, nn.Conv2d):
                nn.init.kaiming_normal_(ly.weight, a=1)

    def forward(self, x):
        '''
        x: imgs (Batch, H, W, 3)
        '''
        out = F.conv2d(x, self.kernel, stride=1, padding=2, groups=self.inc)
        out = self.truc(out)
        out = self.out_conv(out)

        return out

    def _build_kernel(self, inc):
        # filter1: KB
        filter1 = [[0, 0, 0, 0, 0],
                   [0, -1, 2, -1, 0],
                   [0, 2, -4, 2, 0],
                   [0, -1, 2, -1, 0],
                   [0, 0, 0, 0, 0]]
        # filter2：KV
        filter2 = [[-1, 2, -2, 2, -1],
                   [2, -6, 8, -6, 2],
                   [-2, 8, -12, 8, -2],
                   [2, -6, 8, -6, 2],
                   [-1, 2, -2, 2, -1]]
        # # filter3：hor 2rd
        filter3 = [[0, 0, 0, 0, 0],
                   [0, 0, 0, 0, 0],
                   [0, 1, -2, 1, 0],
                   [0, 0, 0, 0, 0],
                   [0, 0, 0, 0, 0]]

        filter1 = np.asarray(filter1, dtype=float) / 4.
        filter2 = np.asarray(filter2, dtype=float) / 12.
        filter3 = np.asarray(filter3, dtype=float) / 2.
        # statck the filters
        filters = [[filter1],  # , filter1, filter1],
                   [filter2],  # , filter2, filter2],
                   [filter3]]  # , filter3, filter3]]  # (3,3,5,5)
        filters = np.array(filters)
        # filters = np.repeat(filters, inc, axis=1)
        filters = np.repeat(filters, inc, axis=0)
        filters = torch.FloatTensor(filters)    # (3,3,5,5)
        # print(filters.size())
        return filters


if __name__ == '__main__':
    x = torch.rand(1, 3, 224, 224)
    srm = SRMConv2d_simple()
    output = srm(x)
    output = np.array(output)
    print(output.shape)

  └── 文件路径: S:\Notes\HFUT\Experiment\_228\SSP-AI-Generated-Image-Detection\networks\ssp.py
     文件内容:
  import torch
from torch import nn
from networks.resnet import resnet50
from networks.srm_conv import SRMConv2d_simple
import torch.nn.functional as F


class ssp(nn.Module):
    def __init__(self, pretrain=True):
        super().__init__()
        self.srm = SRMConv2d_simple()
        self.disc = resnet50(pretrained=True)
        self.disc.fc = nn.Linear(2048, 1)

    def forward(self, x):
        x = F.interpolate(x, (256, 256), mode='bilinear')
        x = self.srm(x)
        x = self.disc(x)
        return x


if __name__ == '__main__':
    model = ssp(pretrain=True)
    print(model)


└── 文件路径: S:\Notes\HFUT\Experiment\_228\SSP-AI-Generated-Image-Detection\options.py
   文件内容:
import argparse
import os
import torch


class TrainOptions():
    def __init__(self):
        self.initialized = False

    def initialize(self, parser):
        # data augmentation
        parser.add_argument('--name', type=str, default='experiment_name',
                            help='name of the experiment. It decides where to store samples and models')
        parser.add_argument('--rz_interp', default='bilinear')
        parser.add_argument('--blur_prob', type=float, default=0)
        parser.add_argument('--blur_sig', default=[0, 1])
        parser.add_argument('--jpg_prob', type=float, default=0)
        parser.add_argument('--jpg_method', default=['pil', 'cv2'])
        parser.add_argument('--jpg_qual', default=[90, 100])
        parser.add_argument('--CropSize', type=int,
                            default=224, help='scale images to this size')
        # train setting
        parser.add_argument('--batchsize', type=int,
                            default=64, help='input batch size')
        parser.add_argument('--choices', default=[0, 0, 0, 0, 1, 0, 0, 0])
        parser.add_argument('--epoch', type=int, default=30)
        parser.add_argument('--lr', default=1e-4)
        parser.add_argument('--trainsize', type=int, default=256)
        parser.add_argument('--load', type=str,
                            default=None)
        parser.add_argument('--image_root', type=str,
                            default='/data/chenjiaxuan/data/genImage')
        parser.add_argument('--save_path', type=str,
                            default='./snapshot/sortnet/')
        parser.add_argument('--isPatch', action='store_false')
        parser.add_argument('--patch_size', default=32)
        parser.add_argument('--aug', action='store_false')
        parser.add_argument('--gpu_id', type=str, default='3')
        parser.add_argument('--log_name', default='log3.log',
                            help='rename the logfile', type=str)
        parser.add_argument('--val_interval', default=1,
                            type=int, help='val per interval')
        parser.add_argument('--val_batchsize', default=64, type=int)
        return parser

    def gather_options(self):
        # initialize parser with basic options
        if not self.initialized:
            parser = argparse.ArgumentParser(
                formatter_class=argparse.ArgumentDefaultsHelpFormatter)
            parser = self.initialize(parser)

        # get the basic options
        opt, _ = parser.parse_known_args()
        self.parser = parser

        return parser.parse_args()

    def print_options(self, opt):
        message = ''
        message += '----------------- Options ---------------\n'
        for k, v in sorted(vars(opt).items()):
            comment = ''
            default = self.parser.get_default(k)
            if v != default:
                comment = '\t[default: %s]' % str(default)
            message += '{:>25}: {:<30}{}\n'.format(str(k), str(v), comment)
        message += '----------------- End -------------------'
        print(message)

    def parse(self, print_options=True):

        opt = self.gather_options()
        opt.isTrain = True   # train or test
        opt.isVal = False
        # opt.classes = opt.classes.split(',')

        # # result dir, save results and opt
        # opt.results_dir = f"./results/{opt.detect_method}"
        # util.mkdir(opt.results_dir)

        if print_options:
            self.print_options(opt)

        # additional

        # opt.rz_interp = opt.rz_interp.split(',')
        # opt.blur_sig = [float(s) for s in opt.blur_sig.split(',')]
        # opt.jpg_method = opt.jpg_method.split(',')
        # opt.jpg_qual = [int(s) for s in opt.jpg_qual.split(',')]
        # if len(opt.jpg_qual) == 2:
        #     opt.jpg_qual = list(range(opt.jpg_qual[0], opt.jpg_qual[1] + 1))
        # elif len(opt.jpg_qual) > 2:
        #     raise ValueError(
        #         "Shouldn't have more than 2 values for --jpg_qual.")

        self.opt = opt
        return self.opt


└── 文件路径: S:\Notes\HFUT\Experiment\_228\SSP-AI-Generated-Image-Detection\README.md
   文件内容:
# SSP-AI-Generated-Image-Detection

This is the official implementation for the following research paper:

> **A Single Simple Patch is All You Need for AI-generated Image Detection** [[arxiv]](https://arxiv.org/pdf/2402.01123.pdf)
>
> Jiaxuan Chen, Jieteng Yao, and Li Niu<br>

Note that in the paper, we proposed Enhanced SSP (ESSP) to improve its robustness against blur and compression. Currently, we only release the code of SSP (the flowchart is shown in the following figure). The code of ESSP will be released soon. 

<div align="center">
  <img src='./figures/pipeline.png' align="center" width=800>
</div>

## Environment Setup
You can install the required packages by running the command:
```bash
pip install -r requirements.txt
```
## Dataset
The training set and testing set used in the paper can be downloaded from [GenImage](https://github.com/GenImage-Dataset/GenImage). This dataset contains data from eight generators. 
After downloading the dataset, you need to specify the root path in the options. The dataset can be organized as follows:
```bash
GenImage/
├── imagenet_ai_0419_biggan
    ├── train
        ├── ai
        ├── nature
    ├── val
        ├── ai
        ├── nature
└── imagenet_ai_0419_sdv4
    ├── train
        ├── ai
        ├── nature
    ├── val
        ├── ai
        ├── nature
└── imagenet_ai_0419_vqdm
    ...
└── imagenet_ai_0424_sdv5
    ...
└── imagenet_ai_0424_wukong
    ...
└── imagenet_ai_0508_adm
    ...
└── imagenet_glide
    ...
└── imagenet_midjourney
    ...
```
## Training and Validation
You can simply run the following script to train and validate your model:
```bash
sh train_val.sh
```
## Testing
You can simply run the following script to test your model:
```bash
sh test.sh
```
Our pretrained models on eight dataests can be downloaded from [Baidu Cloud](https://pan.baidu.com/s/1Wk2Cqeav_wVxPMPNy-zHZQ?pwd=bcmi) (code:bcmi) or [OneDrive](https://1drv.ms/f/s!Aq2pxrmMfMvRh29sp4zHSlbJRlP7?e=C3aHEp). 

## Results on GenImage
The results of ResNet50 baseline and our SSP method with different training and test subsets. In each slot, the left number is the result of ResNet50 and the right number is the result of our SSP. 
<div align="center">
  <img src='./figures/results.png' align="center" width=900>
</div>


└── 文件路径: S:\Notes\HFUT\Experiment\_228\SSP-AI-Generated-Image-Detection\requirements.txt
   文件内容:
numpy==1.24.4
opencv_python==4.8.1.78
opencv_python_headless==4.9.0.80
# Pillow==10.0.1
Pillow==10.3.0
scipy==1.10.1
torch==1.12.1
torchvision==0.13.1


└── 文件路径: S:\Notes\HFUT\Experiment\_228\SSP-AI-Generated-Image-Detection\test.py
   文件内容:
import os
import torch
from utils.util import set_random_seed, poly_lr
from utils.tdataloader import get_loader, get_val_loader
from options import TrainOptions
from networks.ssp import ssp
from utils.loss import bceLoss
from datetime import datetime
import numpy as np
"""Currently assumes jpg_prob, blur_prob 0 or 1"""
from PIL import ImageFile
ImageFile.LOAD_TRUNCATED_IMAGES = True


def get_val_opt():
    val_opt = TrainOptions().parse(print_options=False)
    val_opt.isTrain = False
    val_opt.isVal = True
    # blur
    val_opt.blur_prob = 0
    val_opt.blur_sig = [1]
    # jpg
    val_opt.jpg_prob = 0
    val_opt.jpg_method = ['pil']
    val_opt.jpg_qual = [90]
    # if len(val_opt.blur_sig) == 2:
    #     b_sig = val_opt.blur_sig
    #     val_opt.blur_sig = [(b_sig[0] + b_sig[1]) / 2]
    # if len(val_opt.jpg_qual) != 1:
    #     j_qual = val_opt.jpg_qual
    #     val_opt.jpg_qual = [int((j_qual[0] + j_qual[-1]) / 2)]

    return val_opt


def val(val_loader, model, save_path):
    model.eval()
    total_right_image = total_image = 0
    with torch.no_grad():
        for loader in val_loader:
            right_ai_image = right_nature_image = 0
            name, val_ai_loader, ai_size, val_nature_loader, nature_size = loader['name'], loader[
                'val_ai_loader'], loader['ai_size'], loader['val_nature_loader'], loader['nature_size']
            print("val on:", name)
            # for images, labels in tqdm(val_ai_loader, desc='val_ai'):
            for images, labels in val_ai_loader:
                images = images.cuda()
                labels = labels.cuda()
                res = model(images)
                res = torch.sigmoid(res).ravel()
                right_ai_image += (((res > 0.5) & (labels == 1))
                                   | ((res < 0.5) & (labels == 0))).sum()

            print(f'ai accu: {right_ai_image/ai_size}')
            # for images,labels in tqdm(val_nature_loader,desc='val_nature'):
            for images, labels in val_nature_loader:
                images = images.cuda()
                labels = labels.cuda()
                res = model(images)
                res = torch.sigmoid(res).ravel()
                right_nature_image += (((res > 0.5) & (labels == 1))
                                       | ((res < 0.5) & (labels == 0))).sum()
            print(f'nature accu:{right_nature_image/nature_size}')
            accu = (right_ai_image + right_nature_image) / \
                (ai_size + nature_size)
            total_right_image += right_ai_image + right_nature_image
            total_image += ai_size + nature_size
            print(f'val on:{name}, Accuracy:{accu}')
    total_accu = total_right_image / total_image
    print(f'Accuracy:{total_accu}')


if __name__ == '__main__':
    set_random_seed()
    # train and val options
    opt = TrainOptions().parse()
    val_opt = get_val_opt()

    # load data
    print('load data...')

    val_loader = get_val_loader(val_opt)

    # cuda config
    # set the device for training
    if opt.gpu_id == '0':
        os.environ["CUDA_VISIBLE_DEVICES"] = "0"
        print('USE GPU 0')
    elif opt.gpu_id == '1':
        os.environ["CUDA_VISIBLE_DEVICES"] = "1"
        print('USE GPU 1')
    elif opt.gpu_id == '2':
        os.environ["CUDA_VISIBLE_DEVICES"] = "2"
        print('USE GPU 2')
    elif opt.gpu_id == '3':
        os.environ["CUDA_VISIBLE_DEVICES"] = "3"
        print('USE GPU 3')

    # load model
    model = ssp().cuda()
    if opt.load is not None:
        model.load_state_dict(torch.load(opt.load))
        print('load model from', opt.load)
    optimizer = torch.optim.Adam(model.parameters(), opt.lr)
    save_path = opt.save_path
    if not os.path.exists(save_path):
        os.makedirs(save_path)
    print("Start train")
    val(val_loader, model, save_path)


└── 文件路径: S:\Notes\HFUT\Experiment\_228\SSP-AI-Generated-Image-Detection\test.sh
   文件内容:
python test.py --blur_prob=0 --jpg_prob=0 --val_batchsize=64 --patchsize=32 --load='snapshots/xxx'

└── 文件路径: S:\Notes\HFUT\Experiment\_228\SSP-AI-Generated-Image-Detection\train_val.py
   文件内容:
import os
import torch
from utils.util import set_random_seed, poly_lr
from utils.tdataloader import get_loader, get_val_loader
from options import TrainOptions
from networks.ssp import ssp
from utils.loss import bceLoss
from datetime import datetime
import numpy as np
"""Currently assumes jpg_prob, blur_prob 0 or 1"""
from PIL import ImageFile
ImageFile.LOAD_TRUNCATED_IMAGES = True


def get_val_opt():
    val_opt = TrainOptions().parse(print_options=False)
    val_opt.isTrain = False
    val_opt.isVal = True
    # blur
    val_opt.blur_prob = 0
    val_opt.blur_sig = [1]
    # jpg
    val_opt.jpg_prob = 0
    val_opt.jpg_method = ['pil']
    val_opt.jpg_qual = [90]
    # if len(val_opt.blur_sig) == 2:
    #     b_sig = val_opt.blur_sig
    #     val_opt.blur_sig = [(b_sig[0] + b_sig[1]) / 2]
    # if len(val_opt.jpg_qual) != 1:
    #     j_qual = val_opt.jpg_qual
    #     val_opt.jpg_qual = [int((j_qual[0] + j_qual[-1]) / 2)]

    return val_opt


def train(train_loader, model, optimizer, epoch, save_path):
    model.train()
    global step
    epoch_step = 0
    loss_all = 0
    try:
        for i, (images, labels) in enumerate(train_loader, start=1):
            optimizer.zero_grad()
            images = images.cuda()
            preds = model(images).ravel()
            labels = labels.cuda()
            loss1 = bceLoss()
            loss = loss1(preds, labels)
            loss.backward()
            optimizer.step()
            step += 1
            epoch_step += 1
            loss_all += loss.data
            if i % 200 == 0 or i == total_step or i == 1:
                print(
                    f'{datetime.now()} Epoch [{epoch:03d}/{opt.epoch:03d}], Step [{i:04d}/{total_step:04d}], Total_loss: {loss.data:.4f}')
        loss_all /= epoch_step
        if epoch % 50 == 0:
            torch.save(model.state_dict(), save_path +
                       f'Net_epoch_{epoch}.pth')

    except KeyboardInterrupt:
        print('Keyboard Interrupt: save model and exit.')


def val(val_loader, model, epoch, save_path):
    model.eval()
    global best_epoch, best_accu
    total_right_image = total_image = 0
    with torch.no_grad():
        for loader in val_loader:
            right_ai_image = right_nature_image = 0
            name, val_ai_loader, ai_size, val_nature_loader, nature_size = loader['name'], loader[
                'val_ai_loader'], loader['ai_size'], loader['val_nature_loader'], loader['nature_size']
            print("val on:", name)
            # for images, labels in tqdm(val_ai_loader, desc='val_ai'):
            for images, labels in val_ai_loader:
                images = images.cuda()
                labels = labels.cuda()
                res = model(images)
                res = torch.sigmoid(res).ravel()
                right_ai_image += (((res > 0.5) & (labels == 1))
                                   | ((res < 0.5) & (labels == 0))).sum()

            print(f'ai accu: {right_ai_image/ai_size}')
            # for images,labels in tqdm(val_nature_loader,desc='val_nature'):
            for images, labels in val_nature_loader:
                images = images.cuda()
                labels = labels.cuda()
                res = model(images)
                res = torch.sigmoid(res).ravel()
                right_nature_image += (((res > 0.5) & (labels == 1))
                                       | ((res < 0.5) & (labels == 0))).sum()
            print(f'nature accu:{right_nature_image/nature_size}')
            accu = (right_ai_image + right_nature_image) / \
                (ai_size + nature_size)
            total_right_image += right_ai_image + right_nature_image
            total_image += ai_size + nature_size
            print(f'val on:{name}, Epoch:{epoch}, Accuracy:{accu}')
    total_accu = total_right_image / total_image
    if epoch == 1:
        best_accu = total_accu
        best_epoch = 1
        torch.save(model.state_dict(), save_path +
                   'Net_epoch_best.pth')
        print(f'Save state_dict successfully! Best epoch:{epoch}.')
    else:
        if total_accu > best_accu:
            best_accu = total_accu
            best_epoch = epoch
            torch.save(model.state_dict(), save_path +
                       'Net_epoch_best.pth')
            print(f'Save state_dict successfully! Best epoch:{epoch}.')
    print(
        f'Epoch:{epoch},Accuracy:{total_accu}, bestEpoch:{best_epoch}, bestAccu:{best_accu}')


if __name__ == '__main__':
    set_random_seed()
    # train and val options
    opt = TrainOptions().parse()
    val_opt = get_val_opt()

    # load data
    print('load data...')
    train_loader = get_loader(opt)
    total_step = len(train_loader)
    val_loader = get_val_loader(val_opt)

    # cuda config
    # set the device for training
    if opt.gpu_id == '0':
        os.environ["CUDA_VISIBLE_DEVICES"] = "0"
        print('USE GPU 0')
    elif opt.gpu_id == '1':
        os.environ["CUDA_VISIBLE_DEVICES"] = "1"
        print('USE GPU 1')
    elif opt.gpu_id == '2':
        os.environ["CUDA_VISIBLE_DEVICES"] = "2"
        print('USE GPU 2')
    elif opt.gpu_id == '3':
        os.environ["CUDA_VISIBLE_DEVICES"] = "3"
        print('USE GPU 3')

    # load model
    model = ssp().cuda()
    if opt.load is not None:
        model.load_state_dict(torch.load(opt.load))
        print('load model from', opt.load)
    optimizer = torch.optim.Adam(model.parameters(), opt.lr)
    save_path = opt.save_path
    if not os.path.exists(save_path):
        os.makedirs(save_path)

    step = 0
    best_epoch = 0
    best_accu = 0
    print("Start train")
    for epoch in range(1, opt.epoch + 1):
        cur_lr = poly_lr(optimizer, opt.lr, epoch, opt.epoch)
        train(train_loader, model, optimizer, epoch, save_path)
        val(val_loader, model, epoch, save_path)


└── 文件路径: S:\Notes\HFUT\Experiment\_228\SSP-AI-Generated-Image-Detection\train_val.sh
   文件内容:
python train_val.py --blur_prob=0 --jpg_prob=0 --batchsize=64 --epoch=30 --lr=1e-4 --patchsize=32 

└── 目录: S:\Notes\HFUT\Experiment\_228\SSP-AI-Generated-Image-Detection\utils
  └── 文件路径: S:\Notes\HFUT\Experiment\_228\SSP-AI-Generated-Image-Detection\utils\loss.py
     文件内容:
  import torch
from torch import nn
import torch.nn.functional as F


def bceLoss():
    return nn.BCEWithLogitsLoss()


def crossEntropyLoss():
    return nn.CrossEntropyLoss()
def mseLoss():
    return nn.MSELoss()

  └── 文件路径: S:\Notes\HFUT\Experiment\_228\SSP-AI-Generated-Image-Detection\utils\patch.py
     文件内容:
  import numpy as np
import math
from torchvision.transforms import transforms
from PIL import Image


def compute(patch):
    weight, height = patch.size
    m = weight
    res = 0
    patch = np.array(patch).astype(np.int64)
    diff_horizontal = np.sum(np.abs(patch[:, :-1, :] - patch[:, 1:, :]))
    diff_vertical = np.sum(np.abs(patch[:-1, :, :] - patch[1:, :, :]))
    diff_diagonal = np.sum(np.abs(patch[:-1, :-1, :] - patch[1:, 1:, :]))
    diff_diagonal += np.sum(np.abs(patch[1:, :-1, :] - patch[:-1, 1:, :]))
    res = diff_horizontal + diff_vertical + diff_diagonal
    return res.sum()


def patch_img(img, patch_size, height):
    img_width, img_height = img.size
    num_patch = (height // patch_size) * (height // patch_size)
    patch_list = []
    min_len = min(img_height, img_width)
    rz = transforms.Resize((height, height))
    if min_len < patch_size:
        img = rz(img)
    rp = transforms.RandomCrop(patch_size)
    for i in range(num_patch):
        patch_list.append(rp(img))
    patch_list.sort(key=lambda x: compute(x), reverse=False)
    new_img = patch_list[0]

    return new_img


  └── 文件路径: S:\Notes\HFUT\Experiment\_228\SSP-AI-Generated-Image-Detection\utils\tdataloader.py
     文件内容:
  from torch.utils.data import Dataset, DataLoader
import torch
from torchvision import transforms
import os
from utils.patch import patch_img
from PIL import Image
import numpy as np
import cv2
import random as rd
from random import random, choice
from scipy.ndimage.filters import gaussian_filter
from io import BytesIO
mp = {0: 'imagenet_ai_0508_adm', 1: 'imagenet_ai_0419_biggan', 2: 'imagenet_glide', 3: 'imagenet_midjourney',
      4: 'imagenet_ai_0419_sdv4', 5: 'imagenet_ai_0424_sdv5', 6: 'imagenet_ai_0419_vqdm', 7: 'imagenet_ai_0424_wukong',
      8: 'imagenet_DALLE2'
      }


def sample_continuous(s):
    if len(s) == 1:
        return s[0]
    if len(s) == 2:
        rg = s[1] - s[0]
        return random() * rg + s[0]
    raise ValueError("Length of iterable s should be 1 or 2.")


def sample_discrete(s):
    if len(s) == 1:
        return s[0]
    return choice(s)


def sample_randint(s):
    if len(s) == 1:
        return s[0]
    return rd.randint(s[0], s[1])


def gaussian_blur_gray(img, sigma):
    if len(img.shape) == 3:
        img_blur = np.zeros_like(img)
        for i in range(img.shape[2]):
            img_blur[:, :, i] = gaussian_filter(img[:, :, i], sigma=sigma)
    else:
        img_blur = gaussian_filter(img, sigma=sigma)
    return img_blur


def gaussian_blur(img, sigma):
    gaussian_filter(img[:, :, 0], output=img[:, :, 0], sigma=sigma)
    gaussian_filter(img[:, :, 1], output=img[:, :, 1], sigma=sigma)
    gaussian_filter(img[:, :, 2], output=img[:, :, 2], sigma=sigma)


def cv2_jpg(img, compress_val):
    img_cv2 = img[:, :, ::-1]
    encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), compress_val]
    result, encimg = cv2.imencode('.jpg', img_cv2, encode_param)
    decimg = cv2.imdecode(encimg, 1)
    return decimg[:, :, ::-1]


def pil_jpg(img, compress_val):
    out = BytesIO()
    img = Image.fromarray(img)
    img.save(out, format='jpeg', quality=compress_val)
    img = Image.open(out)
    # load from memory before ByteIO closes
    img = np.array(img)
    out.close()
    return img


jpeg_dict = {'cv2': cv2_jpg, 'pil': pil_jpg}


def jpeg_from_key(img, compress_val, key):
    method = jpeg_dict[key]
    return method(img, compress_val)


def data_augment(img, opt):
    img = np.array(img)

    if random() < opt.blur_prob:
        sig = sample_continuous(opt.blur_sig)
        gaussian_blur(img, sig)

    if random() < opt.jpg_prob:
        method = sample_discrete(opt.jpg_method)
        qual = sample_randint(opt.jpg_qual)
        img = jpeg_from_key(img, qual, method)

    return Image.fromarray(img)


def processing(img, opt):
    if opt.aug:
        aug = transforms.Lambda(
            lambda img: data_augment(img, opt)
        )
    else:
        aug = transforms.Lambda(
            lambda img: img
        )

    if opt.isPatch:
        patch_func = transforms.Lambda(
            lambda img: patch_img(img, opt.patch_size, opt.trainsize))
    else:
        patch_func = transforms.Resize((256, 256))

    trans = transforms.Compose([
        aug,
        patch_func,
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406],
                             [0.229, 0.224, 0.225]),
    ])

    return trans(img)


class genImageTrainDataset(Dataset):
    def __init__(self, image_root, image_dir, opt):
        super().__init__()
        self.opt = opt
        self.root = os.path.join(image_root, image_dir, "train")
        self.nature_path = os.path.join(self.root, "nature")
        self.nature_list = [os.path.join(self.nature_path, f)
                            for f in os.listdir(self.nature_path)]
        self.nature_size = len(self.nature_list)
        self.ai_path = os.path.join(self.root, "ai")
        self.ai_list = [os.path.join(self.ai_path, f)
                        for f in os.listdir(self.ai_path)]
        self.ai_size = len(self.ai_list)
        self.images = self.nature_list + self.ai_list
        self.labels = torch.cat(
            (torch.ones(self.nature_size), torch.zeros(self.ai_size)))

    def rgb_loader(self, path):
        with open(path, 'rb') as f:
            img = Image.open(f)
            return img.convert('RGB')

    def __getitem__(self, index):
        try:
            image = self.rgb_loader(self.images[index])
            label = self.labels[index]
        except:
            new_index = index - 1
            image = self.rgb_loader(
                self.images[max(0, new_index)])
            label = self.labels[max(0, new_index)]
        image = processing(image, self.opt)
        return image, label

    def __len__(self):
        return self.nature_size + self.ai_size


class genImageValDataset(Dataset):
    def __init__(self, image_root, image_dir, is_real, opt):
        super().__init__()
        self.opt = opt
        self.root = os.path.join(image_root, image_dir, "val")
        if is_real:
            self.img_path = os.path.join(self.root, 'nature')
            self.img_list = [os.path.join(self.img_path, f)
                             for f in os.listdir(self.img_path)]
            self.img_len = len(self.img_list)
            self.labels = torch.ones(self.img_len)
        else:
            self.img_path = os.path.join(self.root, 'ai')
            self.img_list = [os.path.join(self.img_path, f)
                             for f in os.listdir(self.img_path)]
            self.img_len = len(self.img_list)
            self.labels = torch.zeros(self.img_len)

    def rgb_loader(self, path):
        with open(path, 'rb') as f:
            img = Image.open(f)
            return img.convert('RGB')

    def __getitem__(self, index):
        image = self.rgb_loader(self.img_list[index])
        label = self.labels[index]
        image = processing(image, self.opt)
        return image, label

    def __len__(self):
        return self.img_len


class genImageTestDataset(Dataset):
    def __init__(self, image_root, image_dir, opt):
        super().__init__()
        self.opt = opt
        self.root = os.path.join(image_root, image_dir, "val")
        self.nature_path = os.path.join(self.root, "nature")
        self.nature_list = [os.path.join(self.nature_path, f)
                            for f in os.listdir(self.nature_path)]
        self.nature_size = len(self.nature_list)
        self.ai_path = os.path.join(self.root, "ai")
        self.ai_list = [os.path.join(self.ai_path, f)
                        for f in os.listdir(self.ai_path)]
        self.ai_size = len(self.ai_list)
        self.images = self.nature_list + self.ai_list
        self.labels = torch.cat(
            (torch.ones(self.nature_size), torch.zeros(self.ai_size)))

    def rgb_loader(self, path):
        with open(path, 'rb') as f:
            img = Image.open(f)
            return img.convert('RGB')

    def __getitem__(self, index):
        try:
            image = self.rgb_loader(self.images[index])
            label = self.labels[index]
        except:
            new_index = index - 1
            image = self.rgb_loader(
                self.images[max(0, new_index)])
            label = self.labels[max(0, new_index)]
        image = processing(image, self.opt)
        return image, label, self.images[index]

    def __len__(self):
        return self.nature_size + self.ai_size


def get_single_loader(opt, image_dir, is_real):
    val_dataset = genImageValDataset(
        opt.image_root, image_dir=image_dir, is_real=is_real, opt=opt)
    val_loader = DataLoader(val_dataset, batch_size=opt.val_batchsize,
                            shuffle=False, num_workers=4, pin_memory=True)
    return val_loader, len(val_dataset)


def get_val_loader(opt):
    choices = opt.choices
    loader = []
    for i, choice in enumerate(choices):
        datainfo = dict()
        if choice == 0 or choice == 1:
            print("val on:", mp[i])
            datainfo['name'] = mp[i]
            datainfo['val_ai_loader'], datainfo['ai_size'] = get_single_loader(
                opt, datainfo['name'], is_real=False)
            datainfo['val_nature_loader'], datainfo['nature_size'] = get_single_loader(
                opt, datainfo['name'], is_real=True)
            loader.append(datainfo)
    return loader


def get_loader(opt):
    choices = opt.choices
    image_root = opt.image_root

    datasets = []
    if choices[0] == 1:
        adm_dataset = genImageTrainDataset(
            image_root, "imagenet_ai_0508_adm", opt=opt)
        datasets.append(adm_dataset)
        print("train on: imagenet_ai_0508_adm")
    if choices[1] == 1:
        biggan_dataset = genImageTrainDataset(
            image_root, "imagenet_ai_0419_biggan", opt=opt)
        datasets.append(biggan_dataset)
        print("train on: imagenet_ai_0419_biggan")
    if choices[2] == 1:
        glide_dataset = genImageTrainDataset(
            image_root, "imagenet_glide", opt=opt)
        datasets.append(glide_dataset)
        print("train on: imagenet_glide")
    if choices[3] == 1:
        midjourney_dataset = genImageTrainDataset(
            image_root, "imagenet_midjourney", opt=opt)
        datasets.append(midjourney_dataset)
        print("train on: imagenet_midjourney")
    if choices[4] == 1:
        sdv14_dataset = genImageTrainDataset(
            image_root, "imagenet_ai_0419_sdv4", opt=opt)
        datasets.append(sdv14_dataset)
        print("train on: imagenet_ai_0419_sdv4")
    if choices[5] == 1:
        sdv15_dataset = genImageTrainDataset(
            image_root, "imagenet_ai_0424_sdv5", opt=opt)
        datasets.append(sdv15_dataset)
        print("train on: imagenet_ai_0424_sdv5")
    if choices[6] == 1:
        vqdm_dataset = genImageTrainDataset(
            image_root, "imagenet_ai_0419_vqdm", opt=opt)
        datasets.append(vqdm_dataset)
        print("train on: imagenet_ai_0419_vqdm")
    if choices[7] == 1:
        wukong_dataset = genImageTrainDataset(
            image_root, "imagenet_ai_0424_wukong", opt=opt)
        datasets.append(wukong_dataset)
        print("train on: imagenet_ai_0424_wukong")

    train_dataset = torch.utils.data.ConcatDataset(datasets)
    train_loader = DataLoader(train_dataset, batch_size=opt.batchsize,
                              shuffle=True, num_workers=4, pin_memory=True)
    return train_loader


def get_test_loader(opt):
    choices = opt.choices
    image_root = opt.image_root
    datasets = []
    if choices[0] == 2:
        adm_dataset = genImageTestDataset(
            image_root, "imagenet_ai_0508_adm", opt=opt)
        datasets.append(adm_dataset)
        print("test on: imagenet_ai_0508_adm")
    if choices[1] == 2:
        biggan_dataset = genImageTestDataset(
            image_root, "imagenet_ai_0419_biggan", opt=opt)
        datasets.append(biggan_dataset)
        print("test on: imagenet_ai_0419_biggan")
    if choices[2] == 2:
        glide_dataset = genImageTestDataset(
            image_root, "imagenet_glide", opt=opt)
        datasets.append(glide_dataset)
        print("test on: imagenet_glide")
    if choices[3] == 2:
        midjourney_dataset = genImageTestDataset(
            image_root, "imagenet_midjourney", opt=opt)
        datasets.append(midjourney_dataset)
        print("test on: imagenet_midjourney")
    if choices[4] == 2:
        sdv14_dataset = genImageTestDataset(
            image_root, "imagenet_ai_0419_sdv4", opt=opt)
        datasets.append(sdv14_dataset)
        print("test on: imagenet_ai_0419_sdv4")
    if choices[5] == 2:
        sdv15_dataset = genImageTestDataset(
            image_root, "imagenet_ai_0424_sdv5", opt=opt)
        datasets.append(sdv15_dataset)
        print("test on: imagenet_ai_0424_sdv5")
    if choices[6] == 2:
        vqdm_dataset = genImageTestDataset(
            image_root, "imagenet_ai_0419_vqdm", opt=opt)
        datasets.append(vqdm_dataset)
        print("test on: imagenet_ai_0419_vqdm")
    if choices[7] == 2:
        wukong_dataset = genImageTestDataset(
            image_root, "imagenet_ai_0424_wukong", opt=opt)
        datasets.append(wukong_dataset)
        print("test on: imagenet_ai_0424_wukong")

    test_dataset = torch.utils.data.ConcatDataset(datasets)
    test_loader = DataLoader(test_dataset, batch_size=opt.batchsize,
                             shuffle=True, num_workers=4, pin_memory=True)
    return test_loader


  └── 文件路径: S:\Notes\HFUT\Experiment\_228\SSP-AI-Generated-Image-Detection\utils\util.py
     文件内容:
  import torch
import numpy as np
import random


def poly_lr(optimizer, init_lr, curr_iter, max_iter, power=0.9):
    lr = init_lr * (1 - float(curr_iter) / max_iter) ** power
    for param_group in optimizer.param_groups:
        param_group['lr'] = lr
        cur_lr = lr
    return cur_lr


def clip_gradient(optimizer, grad_clip):
    """
    For calibrating misalignment gradient via cliping gradient technique
    :param optimizer:
    :param grad_clip:
    :return:
    """
    for group in optimizer.param_groups:
        for param in group['params']:
            if param.grad is not None:
                param.grad.data.clamp_(-grad_clip, grad_clip)


def set_random_seed(seed=42):
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.benchmark = False
    torch.backends.cudnn.deterministic = True
    np.random.seed(seed)
    random.seed(seed)


